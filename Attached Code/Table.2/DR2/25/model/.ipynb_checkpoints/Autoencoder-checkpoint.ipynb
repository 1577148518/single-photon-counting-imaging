{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start.......\n",
      "compress rate is: 0.25\n",
      "WARNING:tensorflow:From C:\\Users\\ThinkPad\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      " [*] Reading checkpoints...\n",
      " [!] Load failed...\n",
      "Training...\n",
      "Epoch: [ 1], step: [10], time: [1.0193], loss: [0.27045876]\n",
      "Epoch: [ 1], step: [20], time: [1.7762], loss: [0.26779136]\n",
      "Epoch: [ 1], step: [30], time: [2.2260], loss: [0.27428314]\n",
      "Epoch: [ 1], step: [40], time: [2.6928], loss: [0.25435954]\n",
      "Epoch: [ 1], step: [50], time: [3.2743], loss: [0.25272381]\n",
      "Epoch: [ 1], step: [60], time: [3.7350], loss: [0.24065493]\n",
      "Epoch: [ 1], step: [70], time: [4.1888], loss: [0.22892042]\n",
      "Epoch: [ 2], step: [80], time: [5.1682], loss: [0.21792518]\n",
      "Epoch: [ 2], step: [90], time: [5.6070], loss: [0.20235085]\n",
      "Epoch: [ 2], step: [100], time: [6.0438], loss: [0.18239735]\n",
      "Epoch: [ 2], step: [110], time: [6.4857], loss: [0.16338409]\n",
      "Epoch: [ 2], step: [120], time: [6.9235], loss: [0.14555149]\n",
      "Epoch: [ 2], step: [130], time: [7.3843], loss: [0.13315120]\n",
      "Epoch: [ 2], step: [140], time: [7.8360], loss: [0.11701573]\n",
      "Epoch: [ 3], step: [150], time: [8.7935], loss: [0.09667569]\n",
      "Epoch: [ 3], step: [160], time: [9.2702], loss: [0.08480462]\n",
      "Epoch: [ 3], step: [170], time: [9.7220], loss: [0.06986228]\n",
      "Epoch: [ 3], step: [180], time: [10.1808], loss: [0.05725702]\n",
      "Epoch: [ 3], step: [190], time: [10.7034], loss: [0.04610832]\n",
      "Epoch: [ 3], step: [200], time: [11.2569], loss: [0.03666224]\n",
      "Epoch: [ 3], step: [210], time: [11.7027], loss: [0.03157634]\n",
      "Epoch: [ 3], step: [220], time: [12.1645], loss: [0.02824214]\n",
      "Epoch: [ 4], step: [230], time: [13.2815], loss: [0.02284523]\n",
      "Epoch: [ 4], step: [240], time: [13.8270], loss: [0.02216907]\n",
      "Epoch: [ 4], step: [250], time: [14.3815], loss: [0.01965513]\n",
      "Epoch: [ 4], step: [260], time: [14.9779], loss: [0.02088192]\n",
      "Epoch: [ 4], step: [270], time: [15.4218], loss: [0.02017684]\n",
      "Epoch: [ 4], step: [280], time: [15.8646], loss: [0.02221373]\n",
      "Epoch: [ 4], step: [290], time: [16.3164], loss: [0.01886223]\n",
      "Epoch: [ 5], step: [300], time: [17.4733], loss: [0.01807211]\n",
      "Epoch: [ 5], step: [310], time: [18.0497], loss: [0.02195357]\n",
      "Epoch: [ 5], step: [320], time: [18.4796], loss: [0.01973967]\n",
      "Epoch: [ 5], step: [330], time: [19.0032], loss: [0.02049079]\n",
      "Epoch: [ 5], step: [340], time: [19.5557], loss: [0.02085669]\n",
      "Epoch: [ 5], step: [350], time: [20.0394], loss: [0.02003163]\n",
      "Epoch: [ 5], step: [360], time: [20.5072], loss: [0.02028448]\n",
      "Epoch: [ 5], step: [370], time: [21.0936], loss: [0.02101353]\n",
      "Epoch: [ 6], step: [380], time: [22.0700], loss: [0.01991553]\n",
      "Epoch: [ 6], step: [390], time: [22.5218], loss: [0.01861848]\n",
      "Epoch: [ 6], step: [400], time: [22.9666], loss: [0.02080186]\n",
      "Epoch: [ 6], step: [410], time: [23.4723], loss: [0.01913982]\n",
      "Epoch: [ 6], step: [420], time: [23.9979], loss: [0.01828733]\n",
      "Epoch: [ 6], step: [430], time: [24.4955], loss: [0.02017239]\n",
      "Epoch: [ 6], step: [440], time: [24.9493], loss: [0.02047055]\n",
      "Epoch: [ 7], step: [450], time: [26.0125], loss: [0.02016979]\n",
      "Epoch: [ 7], step: [460], time: [26.4473], loss: [0.01918100]\n",
      "Epoch: [ 7], step: [470], time: [26.8622], loss: [0.01897062]\n",
      "Epoch: [ 7], step: [480], time: [27.2821], loss: [0.01971565]\n",
      "Epoch: [ 7], step: [490], time: [27.6940], loss: [0.01911953]\n",
      "Epoch: [ 7], step: [500], time: [28.1059], loss: [0.01808429]\n",
      "Epoch: [ 7], step: [510], time: [28.5377], loss: [0.01931007]\n",
      "Epoch: [ 8], step: [520], time: [29.4622], loss: [0.02052787]\n",
      "Epoch: [ 8], step: [530], time: [29.9021], loss: [0.02005632]\n",
      "Epoch: [ 8], step: [540], time: [30.3579], loss: [0.01820343]\n",
      "Epoch: [ 8], step: [550], time: [30.9323], loss: [0.02034842]\n",
      "Epoch: [ 8], step: [560], time: [31.3771], loss: [0.02072178]\n",
      "Epoch: [ 8], step: [570], time: [31.8299], loss: [0.01936914]\n",
      "Epoch: [ 8], step: [580], time: [32.2767], loss: [0.01775664]\n",
      "Epoch: [ 8], step: [590], time: [32.7136], loss: [0.01913649]\n",
      "Epoch: [ 9], step: [600], time: [33.7278], loss: [0.01748373]\n",
      "Epoch: [ 9], step: [610], time: [34.2504], loss: [0.01954890]\n",
      "Epoch: [ 9], step: [620], time: [34.6853], loss: [0.01981612]\n",
      "Epoch: [ 9], step: [630], time: [35.2009], loss: [0.01798721]\n",
      "Epoch: [ 9], step: [640], time: [35.7664], loss: [0.01835958]\n",
      "Epoch: [ 9], step: [650], time: [36.3887], loss: [0.01938698]\n",
      "Epoch: [ 9], step: [660], time: [36.8226], loss: [0.01836284]\n",
      "Epoch: [10], step: [670], time: [37.7840], loss: [0.01719500]\n",
      "Epoch: [10], step: [680], time: [38.2258], loss: [0.01878293]\n",
      "Epoch: [10], step: [690], time: [38.6547], loss: [0.01814570]\n",
      "Epoch: [10], step: [700], time: [39.0895], loss: [0.01993529]\n",
      "Epoch: [10], step: [710], time: [39.6081], loss: [0.01955664]\n",
      "Epoch: [10], step: [720], time: [40.0868], loss: [0.01655419]\n",
      "Epoch: [10], step: [730], time: [40.5945], loss: [0.01759297]\n",
      "Epoch: [10], step: [740], time: [41.0433], loss: [0.01707815]\n",
      "Epoch: [11], step: [750], time: [42.1084], loss: [0.01818640]\n",
      "Epoch: [11], step: [760], time: [42.7008], loss: [0.01703956]\n",
      "Epoch: [11], step: [770], time: [43.3112], loss: [0.01688422]\n",
      "Epoch: [11], step: [780], time: [43.9026], loss: [0.01739806]\n",
      "Epoch: [11], step: [790], time: [44.4362], loss: [0.01738696]\n",
      "Epoch: [11], step: [800], time: [44.8910], loss: [0.01711160]\n",
      "Epoch: [11], step: [810], time: [45.4216], loss: [0.01682403]\n",
      "Epoch: [12], step: [820], time: [46.3920], loss: [0.01553947]\n",
      "Epoch: [12], step: [830], time: [46.8128], loss: [0.01750549]\n",
      "Epoch: [12], step: [840], time: [47.2327], loss: [0.01864594]\n",
      "Epoch: [12], step: [850], time: [47.6486], loss: [0.01657772]\n",
      "Epoch: [12], step: [860], time: [48.0645], loss: [0.01714069]\n",
      "Epoch: [12], step: [870], time: [48.4983], loss: [0.01474869]\n",
      "Epoch: [12], step: [880], time: [48.9342], loss: [0.01817676]\n",
      "Epoch: [13], step: [890], time: [50.0293], loss: [0.01607481]\n",
      "Epoch: [13], step: [900], time: [50.4701], loss: [0.01685162]\n",
      "Epoch: [13], step: [910], time: [51.0036], loss: [0.01710552]\n",
      "Epoch: [13], step: [920], time: [51.5861], loss: [0.01503082]\n",
      "Epoch: [13], step: [930], time: [52.1516], loss: [0.01657354]\n",
      "Epoch: [13], step: [940], time: [52.6323], loss: [0.01672461]\n",
      "Epoch: [13], step: [950], time: [53.0741], loss: [0.01424323]\n",
      "Epoch: [13], step: [960], time: [53.5897], loss: [0.01689441]\n",
      "Epoch: [14], step: [970], time: [54.5791], loss: [0.01619472]\n",
      "Epoch: [14], step: [980], time: [55.0139], loss: [0.01678049]\n",
      "Epoch: [14], step: [990], time: [55.4428], loss: [0.01718299]\n",
      "Epoch: [14], step: [1000], time: [55.8726], loss: [0.01714985]\n",
      "Epoch: [14], step: [1010], time: [56.2845], loss: [0.01450265]\n",
      "Epoch: [14], step: [1020], time: [56.7114], loss: [0.01718317]\n",
      "Epoch: [14], step: [1030], time: [57.1223], loss: [0.01610309]\n",
      "Epoch: [15], step: [1040], time: [58.2134], loss: [0.01617197]\n",
      "Epoch: [15], step: [1050], time: [58.6502], loss: [0.01554390]\n",
      "Epoch: [15], step: [1060], time: [59.0731], loss: [0.01637665]\n",
      "Epoch: [15], step: [1070], time: [59.4979], loss: [0.01531682]\n",
      "Epoch: [15], step: [1080], time: [59.9278], loss: [0.01584104]\n",
      "Epoch: [15], step: [1090], time: [60.3576], loss: [0.01509100]\n",
      "Epoch: [15], step: [1100], time: [60.8034], loss: [0.01514799]\n",
      "Epoch: [15], step: [1110], time: [61.2433], loss: [0.01514869]\n",
      "Epoch: [16], step: [1120], time: [62.2346], loss: [0.01567193]\n",
      "Epoch: [16], step: [1130], time: [62.7014], loss: [0.01554141]\n",
      "Epoch: [16], step: [1140], time: [63.1641], loss: [0.01488829]\n",
      "Epoch: [16], step: [1150], time: [63.6648], loss: [0.01576053]\n",
      "Epoch: [16], step: [1160], time: [64.1236], loss: [0.01448039]\n",
      "Epoch: [16], step: [1170], time: [64.5923], loss: [0.01523875]\n",
      "Epoch: [16], step: [1180], time: [65.0820], loss: [0.01486642]\n",
      "Epoch: [17], step: [1190], time: [66.2180], loss: [0.01421206]\n",
      "Epoch: [17], step: [1200], time: [66.7545], loss: [0.01505378]\n",
      "Epoch: [17], step: [1210], time: [67.3140], loss: [0.01463143]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [17], step: [1220], time: [67.8795], loss: [0.01459109]\n",
      "Epoch: [17], step: [1230], time: [68.3812], loss: [0.01429842]\n",
      "Epoch: [17], step: [1240], time: [68.8389], loss: [0.01516641]\n",
      "Epoch: [17], step: [1250], time: [69.2907], loss: [0.01389027]\n",
      "Epoch: [18], step: [1260], time: [70.3738], loss: [0.01363423]\n",
      "Epoch: [18], step: [1270], time: [70.8107], loss: [0.01465858]\n",
      "Epoch: [18], step: [1280], time: [71.2605], loss: [0.01444213]\n",
      "Epoch: [18], step: [1290], time: [71.7143], loss: [0.01489990]\n",
      "Epoch: [18], step: [1300], time: [72.1651], loss: [0.01362905]\n",
      "Epoch: [18], step: [1310], time: [72.6248], loss: [0.01365095]\n",
      "Epoch: [18], step: [1320], time: [73.0587], loss: [0.01469262]\n",
      "Epoch: [18], step: [1330], time: [73.5563], loss: [0.01419404]\n",
      "Epoch: [19], step: [1340], time: [74.5048], loss: [0.01433080]\n",
      "Epoch: [19], step: [1350], time: [74.9366], loss: [0.01313833]\n",
      "Epoch: [19], step: [1360], time: [75.3725], loss: [0.01438728]\n",
      "Epoch: [19], step: [1370], time: [75.8163], loss: [0.01474239]\n",
      "Epoch: [19], step: [1380], time: [76.3778], loss: [0.01398379]\n",
      "Epoch: [19], step: [1390], time: [76.8725], loss: [0.01443752]\n",
      "Epoch: [19], step: [1400], time: [77.3761], loss: [0.01459352]\n",
      "Epoch: [20], step: [1410], time: [78.4901], loss: [0.01257221]\n",
      "Epoch: [20], step: [1420], time: [78.9290], loss: [0.01430831]\n",
      "Epoch: [20], step: [1430], time: [79.3598], loss: [0.01316870]\n",
      "Epoch: [20], step: [1440], time: [79.7927], loss: [0.01331584]\n",
      "Epoch: [20], step: [1450], time: [80.2883], loss: [0.01485197]\n",
      "Epoch: [20], step: [1460], time: [80.7421], loss: [0.01398095]\n",
      "Epoch: [20], step: [1470], time: [81.1600], loss: [0.01330181]\n",
      "Epoch: [20], step: [1480], time: [81.5829], loss: [0.01443932]\n",
      "Epoch: [21], step: [1490], time: [82.6590], loss: [0.01269127]\n",
      "Epoch: [21], step: [1500], time: [83.0848], loss: [0.01333669]\n",
      "Epoch: [21], step: [1510], time: [83.6124], loss: [0.01311874]\n",
      "Epoch: [21], step: [1520], time: [84.1131], loss: [0.01366862]\n",
      "Epoch: [21], step: [1530], time: [84.8242], loss: [0.01318542]\n",
      "Epoch: [21], step: [1540], time: [85.3348], loss: [0.01440352]\n",
      "Epoch: [21], step: [1550], time: [85.7707], loss: [0.01461487]\n",
      "Epoch: [22], step: [1560], time: [86.8308], loss: [0.01317847]\n",
      "Epoch: [22], step: [1570], time: [87.2687], loss: [0.01364518]\n",
      "Epoch: [22], step: [1580], time: [87.6985], loss: [0.01216999]\n",
      "Epoch: [22], step: [1590], time: [88.1463], loss: [0.01331422]\n",
      "Epoch: [22], step: [1600], time: [88.7387], loss: [0.01286484]\n",
      "Epoch: [22], step: [1610], time: [89.1596], loss: [0.01503625]\n",
      "Epoch: [22], step: [1620], time: [89.5845], loss: [0.01297764]\n",
      "Epoch: [23], step: [1630], time: [90.5200], loss: [0.01384564]\n",
      "Epoch: [23], step: [1640], time: [90.9538], loss: [0.01317589]\n",
      "Epoch: [23], step: [1650], time: [91.3767], loss: [0.01405528]\n",
      "Epoch: [23], step: [1660], time: [91.8025], loss: [0.01364405]\n",
      "Epoch: [23], step: [1670], time: [92.2274], loss: [0.01270548]\n",
      "Epoch: [23], step: [1680], time: [92.6642], loss: [0.01316306]\n",
      "Epoch: [23], step: [1690], time: [93.0881], loss: [0.01262520]\n",
      "Epoch: [23], step: [1700], time: [93.5060], loss: [0.01265374]\n",
      "Epoch: [24], step: [1710], time: [94.4654], loss: [0.01341908]\n",
      "Epoch: [24], step: [1720], time: [94.8973], loss: [0.01406965]\n",
      "Epoch: [24], step: [1730], time: [95.3131], loss: [0.01427810]\n",
      "Epoch: [24], step: [1740], time: [95.7490], loss: [0.01418987]\n",
      "Epoch: [24], step: [1750], time: [96.1709], loss: [0.01295171]\n",
      "Epoch: [24], step: [1760], time: [96.5887], loss: [0.01305106]\n",
      "Epoch: [24], step: [1770], time: [97.0086], loss: [0.01174871]\n",
      "Epoch: [25], step: [1780], time: [97.9601], loss: [0.01304030]\n",
      "Epoch: [25], step: [1790], time: [98.3909], loss: [0.01364854]\n",
      "Epoch: [25], step: [1800], time: [98.8118], loss: [0.01318326]\n",
      "WARNING:tensorflow:From C:\\Users\\ThinkPad\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "Epoch: [25], step: [1810], time: [99.3863], loss: [0.01247939]\n",
      "Epoch: [25], step: [1820], time: [100.0026], loss: [0.01455098]\n",
      "Epoch: [25], step: [1830], time: [100.4873], loss: [0.01335403]\n",
      "Epoch: [25], step: [1840], time: [100.9132], loss: [0.01412494]\n",
      "Epoch: [25], step: [1850], time: [101.3390], loss: [0.01502592]\n",
      "Epoch: [26], step: [1860], time: [102.2735], loss: [0.01286295]\n",
      "Epoch: [26], step: [1870], time: [102.7114], loss: [0.01336520]\n",
      "Epoch: [26], step: [1880], time: [103.1382], loss: [0.01384070]\n",
      "Epoch: [26], step: [1890], time: [103.5651], loss: [0.01437913]\n",
      "Epoch: [26], step: [1900], time: [103.9810], loss: [0.01235563]\n",
      "Epoch: [26], step: [1910], time: [104.4288], loss: [0.01363601]\n",
      "Epoch: [26], step: [1920], time: [104.8526], loss: [0.01215552]\n",
      "Epoch: [27], step: [1930], time: [105.7941], loss: [0.01285297]\n",
      "Epoch: [27], step: [1940], time: [106.2349], loss: [0.01327548]\n",
      "Epoch: [27], step: [1950], time: [106.6867], loss: [0.01294290]\n",
      "Epoch: [27], step: [1960], time: [107.1136], loss: [0.01278695]\n",
      "Epoch: [27], step: [1970], time: [107.5534], loss: [0.01341804]\n",
      "Epoch: [27], step: [1980], time: [107.9942], loss: [0.01483570]\n",
      "Epoch: [27], step: [1990], time: [108.4211], loss: [0.01365902]\n",
      "Epoch: [28], step: [2000], time: [109.3566], loss: [0.01320226]\n",
      "Epoch: [28], step: [2010], time: [109.7924], loss: [0.01330155]\n",
      "Epoch: [28], step: [2020], time: [110.2253], loss: [0.01197848]\n",
      "Epoch: [28], step: [2030], time: [110.6491], loss: [0.01379917]\n",
      "Epoch: [28], step: [2040], time: [111.0710], loss: [0.01297652]\n",
      "Epoch: [28], step: [2050], time: [111.4929], loss: [0.01419263]\n",
      "Epoch: [28], step: [2060], time: [111.9118], loss: [0.01404174]\n",
      "Epoch: [28], step: [2070], time: [112.3386], loss: [0.01174031]\n",
      "Epoch: [29], step: [2080], time: [113.2761], loss: [0.01356765]\n",
      "Epoch: [29], step: [2090], time: [113.6990], loss: [0.01304400]\n",
      "Epoch: [29], step: [2100], time: [114.1129], loss: [0.01341408]\n",
      "Epoch: [29], step: [2110], time: [114.8291], loss: [0.01287228]\n",
      "Epoch: [29], step: [2120], time: [115.3666], loss: [0.01217598]\n",
      "Epoch: [29], step: [2130], time: [115.8404], loss: [0.01300291]\n",
      "Epoch: [29], step: [2140], time: [116.2583], loss: [0.01217291]\n",
      "Epoch: [30], step: [2150], time: [117.2157], loss: [0.01236895]\n",
      "Epoch: [30], step: [2160], time: [117.7582], loss: [0.01252034]\n",
      "Epoch: [30], step: [2170], time: [118.2310], loss: [0.01206026]\n",
      "Epoch: [30], step: [2180], time: [118.6848], loss: [0.01241873]\n",
      "Epoch: [30], step: [2190], time: [119.1136], loss: [0.01371969]\n",
      "Epoch: [30], step: [2200], time: [119.5544], loss: [0.01228354]\n",
      "Epoch: [30], step: [2210], time: [119.9803], loss: [0.01210719]\n",
      "Epoch: [30], step: [2220], time: [120.4301], loss: [0.01302079]\n",
      "Epoch: [31], step: [2230], time: [121.3756], loss: [0.01305520]\n",
      "Epoch: [31], step: [2240], time: [121.8024], loss: [0.01269872]\n",
      "Epoch: [31], step: [2250], time: [122.2253], loss: [0.01198898]\n",
      "Epoch: [31], step: [2260], time: [122.6681], loss: [0.01266549]\n",
      "Epoch: [31], step: [2270], time: [123.1010], loss: [0.01283160]\n",
      "Epoch: [31], step: [2280], time: [123.5308], loss: [0.01226341]\n",
      "Epoch: [31], step: [2290], time: [123.9607], loss: [0.01277220]\n",
      "Epoch: [32], step: [2300], time: [124.9201], loss: [0.01224111]\n",
      "Epoch: [32], step: [2310], time: [125.3529], loss: [0.01258438]\n",
      "Epoch: [32], step: [2320], time: [125.7788], loss: [0.01226163]\n",
      "Epoch: [32], step: [2330], time: [126.2086], loss: [0.01265681]\n",
      "Epoch: [32], step: [2340], time: [126.6275], loss: [0.01235032]\n",
      "Epoch: [32], step: [2350], time: [127.0574], loss: [0.01210039]\n",
      "Epoch: [32], step: [2360], time: [127.4832], loss: [0.01218216]\n",
      "Epoch: [33], step: [2370], time: [128.4377], loss: [0.01171557]\n",
      "Epoch: [33], step: [2380], time: [128.8825], loss: [0.01127799]\n",
      "Epoch: [33], step: [2390], time: [129.3203], loss: [0.01195703]\n",
      "Epoch: [33], step: [2400], time: [129.7542], loss: [0.01198119]\n",
      "Epoch: [33], step: [2410], time: [130.3457], loss: [0.01226075]\n",
      "Epoch: [33], step: [2420], time: [130.9381], loss: [0.01239458]\n",
      "Epoch: [33], step: [2430], time: [131.4268], loss: [0.01252353]\n",
      "Epoch: [33], step: [2440], time: [131.8526], loss: [0.01175481]\n",
      "Epoch: [34], step: [2450], time: [132.7931], loss: [0.01279026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [34], step: [2460], time: [133.2309], loss: [0.01134593]\n",
      "Epoch: [34], step: [2470], time: [133.6558], loss: [0.01212726]\n",
      "Epoch: [34], step: [2480], time: [134.0787], loss: [0.01155886]\n",
      "Epoch: [34], step: [2490], time: [134.5285], loss: [0.01148648]\n",
      "Epoch: [34], step: [2500], time: [134.9523], loss: [0.01182328]\n",
      "Epoch: [34], step: [2510], time: [135.3802], loss: [0.01298699]\n",
      "Epoch: [35], step: [2520], time: [136.3306], loss: [0.01299378]\n",
      "Epoch: [35], step: [2530], time: [136.7625], loss: [0.01218726]\n",
      "Epoch: [35], step: [2540], time: [137.1844], loss: [0.01102031]\n",
      "Epoch: [35], step: [2550], time: [137.6132], loss: [0.01292254]\n",
      "Epoch: [35], step: [2560], time: [138.0461], loss: [0.01265994]\n",
      "Epoch: [35], step: [2570], time: [138.4719], loss: [0.01157869]\n",
      "Epoch: [35], step: [2580], time: [138.8918], loss: [0.01191909]\n",
      "Epoch: [35], step: [2590], time: [139.3127], loss: [0.01168682]\n",
      "Epoch: [36], step: [2600], time: [140.2671], loss: [0.01220599]\n",
      "Epoch: [36], step: [2610], time: [140.7698], loss: [0.01323363]\n",
      "Epoch: [36], step: [2620], time: [141.1906], loss: [0.01187611]\n",
      "Epoch: [36], step: [2630], time: [141.6195], loss: [0.01154412]\n",
      "Epoch: [36], step: [2640], time: [142.0494], loss: [0.01137334]\n",
      "Epoch: [36], step: [2650], time: [142.4712], loss: [0.01060414]\n",
      "Epoch: [36], step: [2660], time: [142.8901], loss: [0.01134918]\n",
      "Epoch: [37], step: [2670], time: [143.8675], loss: [0.01158248]\n",
      "Epoch: [37], step: [2680], time: [144.3033], loss: [0.01167312]\n",
      "Epoch: [37], step: [2690], time: [144.7441], loss: [0.01143935]\n",
      "Epoch: [37], step: [2700], time: [145.1760], loss: [0.01200614]\n",
      "Epoch: [37], step: [2710], time: [145.8243], loss: [0.01176829]\n",
      "Epoch: [37], step: [2720], time: [146.4865], loss: [0.01055679]\n",
      "Epoch: [37], step: [2730], time: [146.9622], loss: [0.01142293]\n",
      "Epoch: [38], step: [2740], time: [147.9256], loss: [0.01135984]\n",
      "Epoch: [38], step: [2750], time: [148.3734], loss: [0.01117450]\n",
      "Epoch: [38], step: [2760], time: [148.8043], loss: [0.01169763]\n",
      "Epoch: [38], step: [2770], time: [149.2302], loss: [0.01218780]\n",
      "Epoch: [38], step: [2780], time: [149.6799], loss: [0.01132018]\n",
      "Epoch: [38], step: [2790], time: [150.0978], loss: [0.01239388]\n",
      "Epoch: [38], step: [2800], time: [150.5257], loss: [0.01130170]\n",
      "Epoch: [38], step: [2810], time: [150.9655], loss: [0.01253616]\n",
      "Epoch: [39], step: [2820], time: [152.0416], loss: [0.01081635]\n",
      "Epoch: [39], step: [2830], time: [152.4944], loss: [0.01175371]\n",
      "Epoch: [39], step: [2840], time: [152.9412], loss: [0.01204988]\n",
      "Epoch: [39], step: [2850], time: [153.3671], loss: [0.01167279]\n",
      "Epoch: [39], step: [2860], time: [153.7919], loss: [0.01138793]\n",
      "Epoch: [39], step: [2870], time: [154.2238], loss: [0.01112303]\n",
      "Epoch: [39], step: [2880], time: [154.6766], loss: [0.01121305]\n",
      "Epoch: [40], step: [2890], time: [155.6470], loss: [0.01145820]\n",
      "Epoch: [40], step: [2900], time: [156.0828], loss: [0.01183331]\n",
      "Epoch: [40], step: [2910], time: [156.5246], loss: [0.01130105]\n",
      "Epoch: [40], step: [2920], time: [156.9585], loss: [0.01154300]\n",
      "Epoch: [40], step: [2930], time: [157.3814], loss: [0.01212877]\n",
      "Epoch: [40], step: [2940], time: [157.8102], loss: [0.01173075]\n",
      "Epoch: [40], step: [2950], time: [158.2371], loss: [0.01100293]\n",
      "Epoch: [40], step: [2960], time: [158.6789], loss: [0.01123210]\n",
      "Epoch: [41], step: [2970], time: [159.6214], loss: [0.01070688]\n",
      "Epoch: [41], step: [2980], time: [160.0632], loss: [0.01047093]\n",
      "Epoch: [41], step: [2990], time: [160.5150], loss: [0.01130075]\n",
      "Epoch: [41], step: [3000], time: [160.9538], loss: [0.01213075]\n",
      "Epoch: [41], step: [3010], time: [161.5582], loss: [0.00996661]\n",
      "Epoch: [41], step: [3020], time: [162.1616], loss: [0.01206310]\n",
      "Epoch: [41], step: [3030], time: [162.6542], loss: [0.01114640]\n",
      "Epoch: [42], step: [3040], time: [163.6217], loss: [0.01225650]\n",
      "Epoch: [42], step: [3050], time: [164.1951], loss: [0.01161220]\n",
      "Epoch: [42], step: [3060], time: [164.7865], loss: [0.01150019]\n",
      "Epoch: [42], step: [3070], time: [165.3241], loss: [0.01103503]\n",
      "Epoch: [42], step: [3080], time: [165.8467], loss: [0.01150663]\n",
      "Epoch: [42], step: [3090], time: [166.3045], loss: [0.01122399]\n",
      "Epoch: [42], step: [3100], time: [166.8809], loss: [0.01102909]\n",
      "Epoch: [43], step: [3110], time: [168.0558], loss: [0.01004730]\n",
      "Epoch: [43], step: [3120], time: [168.5884], loss: [0.01163406]\n",
      "Epoch: [43], step: [3130], time: [169.1220], loss: [0.01024519]\n",
      "Epoch: [43], step: [3140], time: [169.5797], loss: [0.01139412]\n",
      "Epoch: [43], step: [3150], time: [170.1043], loss: [0.01121647]\n",
      "Epoch: [43], step: [3160], time: [170.5451], loss: [0.01135106]\n",
      "Epoch: [43], step: [3170], time: [170.9959], loss: [0.01077429]\n",
      "Epoch: [43], step: [3180], time: [171.4178], loss: [0.01049896]\n",
      "Epoch: [44], step: [3190], time: [172.3483], loss: [0.01117405]\n",
      "Epoch: [44], step: [3200], time: [172.7762], loss: [0.01115808]\n",
      "Epoch: [44], step: [3210], time: [173.1871], loss: [0.01265420]\n",
      "Epoch: [44], step: [3220], time: [173.6070], loss: [0.01101501]\n",
      "Epoch: [44], step: [3230], time: [174.0199], loss: [0.01080807]\n",
      "Epoch: [44], step: [3240], time: [174.4527], loss: [0.01140520]\n",
      "Epoch: [44], step: [3250], time: [174.8825], loss: [0.01078360]\n",
      "Epoch: [45], step: [3260], time: [175.8161], loss: [0.01052869]\n",
      "Epoch: [45], step: [3270], time: [176.2848], loss: [0.01072948]\n",
      "Epoch: [45], step: [3280], time: [176.8573], loss: [0.01063505]\n",
      "Epoch: [45], step: [3290], time: [177.2871], loss: [0.01122095]\n",
      "Epoch: [45], step: [3300], time: [177.7279], loss: [0.01115602]\n",
      "Epoch: [45], step: [3310], time: [178.3204], loss: [0.01014492]\n",
      "Epoch: [45], step: [3320], time: [178.8918], loss: [0.01158675]\n",
      "Epoch: [45], step: [3330], time: [179.3855], loss: [0.01020757]\n",
      "Epoch: [46], step: [3340], time: [180.3350], loss: [0.01110450]\n",
      "Epoch: [46], step: [3350], time: [180.7608], loss: [0.01118486]\n",
      "Epoch: [46], step: [3360], time: [181.1897], loss: [0.01089210]\n",
      "Epoch: [46], step: [3370], time: [181.6495], loss: [0.01135278]\n",
      "Epoch: [46], step: [3380], time: [182.0723], loss: [0.01030811]\n",
      "Epoch: [46], step: [3390], time: [182.5032], loss: [0.01163499]\n",
      "Epoch: [46], step: [3400], time: [182.9280], loss: [0.01032718]\n",
      "Epoch: [47], step: [3410], time: [183.8845], loss: [0.01096897]\n",
      "Epoch: [47], step: [3420], time: [184.3273], loss: [0.01177158]\n",
      "Epoch: [47], step: [3430], time: [184.7990], loss: [0.01141067]\n",
      "Epoch: [47], step: [3440], time: [185.2598], loss: [0.01119161]\n",
      "Epoch: [47], step: [3450], time: [185.7186], loss: [0.01010907]\n",
      "Epoch: [47], step: [3460], time: [186.1823], loss: [0.01091362]\n",
      "Epoch: [47], step: [3470], time: [186.6471], loss: [0.01079567]\n",
      "Epoch: [48], step: [3480], time: [187.8040], loss: [0.01002676]\n",
      "Epoch: [48], step: [3490], time: [188.2747], loss: [0.01043815]\n",
      "Epoch: [48], step: [3500], time: [188.7176], loss: [0.01051931]\n",
      "Epoch: [48], step: [3510], time: [189.1963], loss: [0.01118168]\n",
      "Epoch: [48], step: [3520], time: [189.6640], loss: [0.01052416]\n",
      "Epoch: [48], step: [3530], time: [190.0999], loss: [0.01102240]\n",
      "Epoch: [48], step: [3540], time: [190.6763], loss: [0.01146246]\n",
      "Epoch: [48], step: [3550], time: [191.3036], loss: [0.00936664]\n",
      "Epoch: [49], step: [3560], time: [192.6760], loss: [0.00977356]\n",
      "Epoch: [49], step: [3570], time: [193.3192], loss: [0.01129801]\n",
      "Epoch: [49], step: [3580], time: [193.9755], loss: [0.01057877]\n",
      "Epoch: [49], step: [3590], time: [194.6906], loss: [0.01018901]\n",
      "Epoch: [49], step: [3600], time: [195.2531], loss: [0.01032357]\n",
      "Epoch: [49], step: [3610], time: [195.9452], loss: [0.01055089]\n",
      "Epoch: [49], step: [3620], time: [196.5107], loss: [0.01050053]\n",
      "Epoch: [50], step: [3630], time: [197.5380], loss: [0.01097405]\n",
      "Epoch: [50], step: [3640], time: [198.0765], loss: [0.00934539]\n",
      "Epoch: [50], step: [3650], time: [198.6440], loss: [0.01171422]\n",
      "Epoch: [50], step: [3660], time: [199.1686], loss: [0.01066247]\n",
      "Epoch: [50], step: [3670], time: [199.6403], loss: [0.01068072]\n",
      "Epoch: [50], step: [3680], time: [200.0602], loss: [0.01096990]\n",
      "Epoch: [50], step: [3690], time: [200.5140], loss: [0.01102877]\n",
      "Epoch: [50], step: [3700], time: [200.9648], loss: [0.01204295]\n",
      "Epoch: [51], step: [3710], time: [201.9282], loss: [0.01028360]\n",
      "Epoch: [51], step: [3720], time: [202.3541], loss: [0.01111025]\n",
      "Epoch: [51], step: [3730], time: [202.7670], loss: [0.01046444]\n",
      "Epoch: [51], step: [3740], time: [203.1849], loss: [0.01026037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [51], step: [3750], time: [203.6067], loss: [0.01027789]\n",
      "Epoch: [51], step: [3760], time: [204.0236], loss: [0.01056087]\n",
      "Epoch: [51], step: [3770], time: [204.4515], loss: [0.01163085]\n",
      "Epoch: [52], step: [3780], time: [205.3910], loss: [0.01072420]\n",
      "Epoch: [52], step: [3790], time: [205.8338], loss: [0.01125705]\n",
      "Epoch: [52], step: [3800], time: [206.2856], loss: [0.01059064]\n",
      "Epoch: [52], step: [3810], time: [206.7144], loss: [0.01130539]\n",
      "Epoch: [52], step: [3820], time: [207.1383], loss: [0.01100186]\n",
      "Epoch: [52], step: [3830], time: [207.5582], loss: [0.00988305]\n",
      "Epoch: [52], step: [3840], time: [207.9790], loss: [0.01051630]\n",
      "Epoch: [53], step: [3850], time: [208.9125], loss: [0.01177782]\n",
      "Epoch: [53], step: [3860], time: [209.3414], loss: [0.01017351]\n",
      "Epoch: [53], step: [3870], time: [209.7673], loss: [0.01029999]\n",
      "Epoch: [53], step: [3880], time: [210.1891], loss: [0.01054859]\n",
      "Epoch: [53], step: [3890], time: [210.6100], loss: [0.01090586]\n",
      "Epoch: [53], step: [3900], time: [211.0249], loss: [0.01037226]\n",
      "Epoch: [53], step: [3910], time: [211.5874], loss: [0.00997895]\n",
      "Epoch: [53], step: [3920], time: [212.1549], loss: [0.01058592]\n",
      "Epoch: [54], step: [3930], time: [213.1841], loss: [0.01123738]\n",
      "Epoch: [54], step: [3940], time: [213.6050], loss: [0.01039878]\n",
      "Epoch: [54], step: [3950], time: [214.0518], loss: [0.01049088]\n",
      "Epoch: [54], step: [3960], time: [214.5046], loss: [0.01097643]\n",
      "Epoch: [54], step: [3970], time: [214.9205], loss: [0.01017833]\n",
      "Epoch: [54], step: [3980], time: [215.3463], loss: [0.01054991]\n",
      "Epoch: [54], step: [3990], time: [215.7672], loss: [0.01111600]\n",
      "Epoch: [55], step: [4000], time: [216.7077], loss: [0.01032556]\n",
      "Epoch: [55], step: [4010], time: [217.1715], loss: [0.00981390]\n",
      "Epoch: [55], step: [4020], time: [217.5903], loss: [0.00895735]\n",
      "Epoch: [55], step: [4030], time: [218.0172], loss: [0.01032857]\n",
      "Epoch: [55], step: [4040], time: [218.4361], loss: [0.00972232]\n",
      "Epoch: [55], step: [4050], time: [218.8480], loss: [0.01098794]\n",
      "Epoch: [55], step: [4060], time: [219.2878], loss: [0.01098662]\n",
      "Epoch: [55], step: [4070], time: [219.7067], loss: [0.01241378]\n",
      "Epoch: [56], step: [4080], time: [220.6332], loss: [0.01004451]\n",
      "Epoch: [56], step: [4090], time: [221.0521], loss: [0.01026938]\n",
      "Epoch: [56], step: [4100], time: [221.4720], loss: [0.00999969]\n",
      "Epoch: [56], step: [4110], time: [221.8888], loss: [0.01056006]\n",
      "Epoch: [56], step: [4120], time: [222.3087], loss: [0.00987444]\n",
      "Epoch: [56], step: [4130], time: [222.7426], loss: [0.00989912]\n",
      "Epoch: [56], step: [4140], time: [223.1545], loss: [0.00911632]\n",
      "Epoch: [57], step: [4150], time: [224.0870], loss: [0.00911854]\n",
      "Epoch: [57], step: [4160], time: [224.5368], loss: [0.00983113]\n",
      "Epoch: [57], step: [4170], time: [224.9606], loss: [0.00946558]\n",
      "Epoch: [57], step: [4180], time: [225.3825], loss: [0.01014092]\n",
      "Epoch: [57], step: [4190], time: [225.8054], loss: [0.01119976]\n",
      "Epoch: [57], step: [4200], time: [226.2372], loss: [0.00930109]\n",
      "Epoch: [57], step: [4210], time: [226.7779], loss: [0.01100418]\n",
      "Epoch: [58], step: [4220], time: [227.9219], loss: [0.01026155]\n",
      "Epoch: [58], step: [4230], time: [228.3577], loss: [0.01125194]\n",
      "Epoch: [58], step: [4240], time: [228.7696], loss: [0.01092241]\n",
      "Epoch: [58], step: [4250], time: [229.1945], loss: [0.01020789]\n",
      "Epoch: [58], step: [4260], time: [229.6173], loss: [0.00995825]\n",
      "Epoch: [58], step: [4270], time: [230.0462], loss: [0.01023253]\n",
      "Epoch: [58], step: [4280], time: [230.4970], loss: [0.00951204]\n",
      "Epoch: [58], step: [4290], time: [230.9318], loss: [0.00953914]\n",
      "Epoch: [59], step: [4300], time: [231.8753], loss: [0.01046585]\n",
      "Epoch: [59], step: [4310], time: [232.2892], loss: [0.01077394]\n",
      "Epoch: [59], step: [4320], time: [232.7041], loss: [0.00968625]\n",
      "Epoch: [59], step: [4330], time: [233.1559], loss: [0.01016553]\n",
      "Epoch: [59], step: [4340], time: [233.5877], loss: [0.01067309]\n",
      "Epoch: [59], step: [4350], time: [234.0176], loss: [0.01080125]\n",
      "Epoch: [59], step: [4360], time: [234.4704], loss: [0.00995875]\n",
      "Epoch: [60], step: [4370], time: [235.4867], loss: [0.01066108]\n",
      "Epoch: [60], step: [4380], time: [235.9863], loss: [0.01035373]\n",
      "Epoch: [60], step: [4390], time: [236.4600], loss: [0.00926793]\n",
      "Epoch: [60], step: [4400], time: [236.9208], loss: [0.00993897]\n",
      "Epoch: [60], step: [4410], time: [237.4015], loss: [0.01023077]\n",
      "Epoch: [60], step: [4420], time: [237.8663], loss: [0.01045531]\n",
      "Epoch: [60], step: [4430], time: [238.5195], loss: [0.01093719]\n",
      "Epoch: [60], step: [4440], time: [239.1917], loss: [0.01012784]\n",
      "Epoch: [61], step: [4450], time: [240.5381], loss: [0.01074398]\n",
      "Epoch: [61], step: [4460], time: [241.1894], loss: [0.01121355]\n",
      "Epoch: [61], step: [4470], time: [241.8207], loss: [0.01027746]\n",
      "Epoch: [61], step: [4480], time: [242.5069], loss: [0.01038509]\n",
      "Epoch: [61], step: [4490], time: [243.0474], loss: [0.01038472]\n",
      "Epoch: [61], step: [4500], time: [243.5690], loss: [0.00945336]\n",
      "Epoch: [61], step: [4510], time: [244.2583], loss: [0.01026582]\n",
      "Epoch: [62], step: [4520], time: [245.3982], loss: [0.01056459]\n",
      "Epoch: [62], step: [4530], time: [245.8750], loss: [0.01017384]\n",
      "Epoch: [62], step: [4540], time: [246.3547], loss: [0.00939535]\n",
      "Epoch: [62], step: [4550], time: [246.7985], loss: [0.01093162]\n",
      "Epoch: [62], step: [4560], time: [247.2493], loss: [0.01021088]\n",
      "Epoch: [62], step: [4570], time: [247.7709], loss: [0.01010205]\n",
      "Epoch: [62], step: [4580], time: [248.2287], loss: [0.00917567]\n",
      "Epoch: [63], step: [4590], time: [249.1991], loss: [0.00936224]\n",
      "Epoch: [63], step: [4600], time: [249.6459], loss: [0.01066603]\n",
      "Epoch: [63], step: [4610], time: [250.0867], loss: [0.01021141]\n",
      "Epoch: [63], step: [4620], time: [250.5435], loss: [0.00965982]\n",
      "Epoch: [63], step: [4630], time: [251.0072], loss: [0.00956558]\n",
      "Epoch: [63], step: [4640], time: [251.5129], loss: [0.00940943]\n",
      "Epoch: [63], step: [4650], time: [251.9467], loss: [0.01006037]\n",
      "Epoch: [63], step: [4660], time: [252.3726], loss: [0.01034926]\n",
      "Epoch: [64], step: [4670], time: [253.3360], loss: [0.01036769]\n",
      "Epoch: [64], step: [4680], time: [253.8965], loss: [0.00983890]\n",
      "Epoch: [64], step: [4690], time: [254.3533], loss: [0.00991058]\n",
      "Epoch: [64], step: [4700], time: [254.8141], loss: [0.00991241]\n",
      "Epoch: [64], step: [4710], time: [255.2589], loss: [0.00996830]\n",
      "Epoch: [64], step: [4720], time: [255.7366], loss: [0.00974583]\n",
      "Epoch: [64], step: [4730], time: [256.2542], loss: [0.01000467]\n",
      "Epoch: [65], step: [4740], time: [257.2256], loss: [0.01015563]\n",
      "Epoch: [65], step: [4750], time: [257.6545], loss: [0.01054715]\n",
      "Epoch: [65], step: [4760], time: [258.0883], loss: [0.00927226]\n",
      "Epoch: [65], step: [4770], time: [258.5441], loss: [0.01020924]\n",
      "Epoch: [65], step: [4780], time: [258.9650], loss: [0.01078959]\n",
      "Epoch: [65], step: [4790], time: [259.4018], loss: [0.00986138]\n",
      "Epoch: [65], step: [4800], time: [259.8586], loss: [0.01076859]\n",
      "Epoch: [65], step: [4810], time: [260.5507], loss: [0.00978474]\n",
      "Epoch: [66], step: [4820], time: [261.7116], loss: [0.00999812]\n",
      "Epoch: [66], step: [4830], time: [262.1375], loss: [0.00933078]\n",
      "Epoch: [66], step: [4840], time: [262.5464], loss: [0.01009801]\n",
      "Epoch: [66], step: [4850], time: [262.9742], loss: [0.01054211]\n",
      "Epoch: [66], step: [4860], time: [263.4340], loss: [0.01047462]\n",
      "Epoch: [66], step: [4870], time: [263.8798], loss: [0.01015793]\n",
      "Epoch: [66], step: [4880], time: [264.3266], loss: [0.00886704]\n",
      "Epoch: [67], step: [4890], time: [265.2871], loss: [0.01010968]\n",
      "Epoch: [67], step: [4900], time: [265.7289], loss: [0.01048390]\n",
      "Epoch: [67], step: [4910], time: [266.1527], loss: [0.00992464]\n",
      "Epoch: [67], step: [4920], time: [266.5856], loss: [0.01041101]\n",
      "Epoch: [67], step: [4930], time: [267.0483], loss: [0.00986470]\n",
      "Epoch: [67], step: [4940], time: [267.4792], loss: [0.00987001]\n",
      "Epoch: [67], step: [4950], time: [267.9090], loss: [0.01010712]\n",
      "Epoch: [68], step: [4960], time: [268.8485], loss: [0.01106360]\n",
      "Epoch: [68], step: [4970], time: [269.2774], loss: [0.00973415]\n",
      "Epoch: [68], step: [4980], time: [269.7022], loss: [0.01049798]\n",
      "Epoch: [68], step: [4990], time: [270.1291], loss: [0.00968502]\n",
      "Epoch: [68], step: [5000], time: [270.5869], loss: [0.00976282]\n",
      "Epoch: [68], step: [5010], time: [271.0008], loss: [0.01020677]\n",
      "Epoch: [68], step: [5020], time: [271.4256], loss: [0.01096420]\n",
      "Epoch: [68], step: [5030], time: [271.9034], loss: [0.00932569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [69], step: [5040], time: [272.9137], loss: [0.00937067]\n",
      "Epoch: [69], step: [5050], time: [273.3625], loss: [0.00909166]\n",
      "Epoch: [69], step: [5060], time: [273.7893], loss: [0.00964995]\n",
      "Epoch: [69], step: [5070], time: [274.4635], loss: [0.01006286]\n",
      "Epoch: [69], step: [5080], time: [275.0081], loss: [0.00964956]\n",
      "Epoch: [69], step: [5090], time: [275.4409], loss: [0.00967914]\n",
      "Epoch: [69], step: [5100], time: [275.8887], loss: [0.01019152]\n",
      "Epoch: [70], step: [5110], time: [277.4236], loss: [0.01059739]\n",
      "Epoch: [70], step: [5120], time: [277.8704], loss: [0.00993948]\n",
      "Epoch: [70], step: [5130], time: [278.2853], loss: [0.00984836]\n",
      "Epoch: [70], step: [5140], time: [278.7221], loss: [0.00914886]\n",
      "Epoch: [70], step: [5150], time: [279.1679], loss: [0.00958442]\n",
      "Epoch: [70], step: [5160], time: [279.5908], loss: [0.01034744]\n",
      "Epoch: [70], step: [5170], time: [280.0416], loss: [0.00951899]\n",
      "Epoch: [70], step: [5180], time: [280.4675], loss: [0.01044856]\n",
      "Epoch: [71], step: [5190], time: [281.4279], loss: [0.00982806]\n",
      "Epoch: [71], step: [5200], time: [281.8587], loss: [0.00937119]\n",
      "Epoch: [71], step: [5210], time: [282.2786], loss: [0.01048416]\n",
      "Epoch: [71], step: [5220], time: [282.7065], loss: [0.01007013]\n",
      "Epoch: [71], step: [5230], time: [283.1403], loss: [0.00950830]\n",
      "Epoch: [71], step: [5240], time: [283.5612], loss: [0.00913432]\n",
      "Epoch: [71], step: [5250], time: [284.0150], loss: [0.00900358]\n",
      "Epoch: [72], step: [5260], time: [284.9614], loss: [0.00918971]\n",
      "Epoch: [72], step: [5270], time: [285.4182], loss: [0.01036424]\n",
      "Epoch: [72], step: [5280], time: [285.9458], loss: [0.00836983]\n",
      "Epoch: [72], step: [5290], time: [286.3787], loss: [0.01035551]\n",
      "Epoch: [72], step: [5300], time: [286.9013], loss: [0.01030618]\n",
      "Epoch: [72], step: [5310], time: [287.5016], loss: [0.01043989]\n",
      "Epoch: [72], step: [5320], time: [288.0422], loss: [0.00966941]\n",
      "Epoch: [73], step: [5330], time: [289.4095], loss: [0.00959504]\n",
      "Epoch: [73], step: [5340], time: [289.8803], loss: [0.00902095]\n",
      "Epoch: [73], step: [5350], time: [290.5315], loss: [0.00987960]\n",
      "Epoch: [73], step: [5360], time: [291.2367], loss: [0.01039214]\n",
      "Epoch: [73], step: [5370], time: [291.7892], loss: [0.00990522]\n",
      "Epoch: [73], step: [5380], time: [292.4245], loss: [0.00869853]\n",
      "Epoch: [73], step: [5390], time: [293.0827], loss: [0.00973839]\n",
      "Epoch: [73], step: [5400], time: [293.7290], loss: [0.00927499]\n",
      "Epoch: [74], step: [5410], time: [295.7456], loss: [0.00982396]\n",
      "Epoch: [74], step: [5420], time: [296.4108], loss: [0.00875467]\n",
      "Epoch: [74], step: [5430], time: [296.9324], loss: [0.00980501]\n",
      "Epoch: [74], step: [5440], time: [297.4490], loss: [0.00938599]\n",
      "Epoch: [74], step: [5450], time: [297.9746], loss: [0.00974715]\n",
      "Epoch: [74], step: [5460], time: [298.5022], loss: [0.00919911]\n",
      "Epoch: [74], step: [5470], time: [298.9710], loss: [0.00954060]\n",
      "Epoch: [75], step: [5480], time: [300.0840], loss: [0.00961794]\n",
      "Epoch: [75], step: [5490], time: [300.5797], loss: [0.01045128]\n",
      "Epoch: [75], step: [5500], time: [301.0973], loss: [0.00970076]\n",
      "Epoch: [75], step: [5510], time: [301.5860], loss: [0.01033945]\n",
      "Epoch: [75], step: [5520], time: [302.0507], loss: [0.00963801]\n",
      "Epoch: [75], step: [5530], time: [302.5604], loss: [0.00894571]\n",
      "Epoch: [75], step: [5540], time: [303.0331], loss: [0.00958772]\n",
      "Epoch: [75], step: [5550], time: [303.5178], loss: [0.00999702]\n",
      "Epoch: [76], step: [5560], time: [304.7216], loss: [0.00871378]\n",
      "Epoch: [76], step: [5570], time: [305.2153], loss: [0.01054536]\n",
      "Epoch: [76], step: [5580], time: [305.6890], loss: [0.00968425]\n",
      "Epoch: [76], step: [5590], time: [306.1578], loss: [0.00962147]\n",
      "Epoch: [76], step: [5600], time: [306.6764], loss: [0.00969973]\n",
      "Epoch: [76], step: [5610], time: [307.1740], loss: [0.01000687]\n",
      "Epoch: [76], step: [5620], time: [307.6498], loss: [0.00903141]\n",
      "Epoch: [77], step: [5630], time: [308.6730], loss: [0.00938495]\n",
      "Epoch: [77], step: [5640], time: [309.1438], loss: [0.01012516]\n",
      "Epoch: [77], step: [5650], time: [309.6026], loss: [0.00950969]\n",
      "Epoch: [77], step: [5660], time: [310.0813], loss: [0.00987627]\n",
      "Epoch: [77], step: [5670], time: [310.5460], loss: [0.00974392]\n",
      "Epoch: [77], step: [5680], time: [310.9888], loss: [0.00962013]\n",
      "Epoch: [77], step: [5690], time: [311.4496], loss: [0.00894811]\n",
      "Epoch: [78], step: [5700], time: [312.4729], loss: [0.00975175]\n",
      "Epoch: [78], step: [5710], time: [313.0463], loss: [0.00929776]\n",
      "Epoch: [78], step: [5720], time: [313.5121], loss: [0.00944228]\n",
      "Epoch: [78], step: [5730], time: [314.0367], loss: [0.00906224]\n",
      "Epoch: [78], step: [5740], time: [314.6720], loss: [0.01019608]\n",
      "Epoch: [78], step: [5750], time: [315.2275], loss: [0.00899261]\n",
      "Epoch: [78], step: [5760], time: [315.7302], loss: [0.01009649]\n",
      "Epoch: [78], step: [5770], time: [316.3884], loss: [0.00944463]\n",
      "Epoch: [79], step: [5780], time: [317.4805], loss: [0.01003604]\n",
      "Epoch: [79], step: [5790], time: [317.9831], loss: [0.00905171]\n",
      "Epoch: [79], step: [5800], time: [318.5486], loss: [0.00945813]\n",
      "Epoch: [79], step: [5810], time: [319.0413], loss: [0.01066701]\n",
      "Epoch: [79], step: [5820], time: [319.5150], loss: [0.00942606]\n",
      "Epoch: [79], step: [5830], time: [320.0506], loss: [0.01008222]\n",
      "Epoch: [79], step: [5840], time: [320.5483], loss: [0.00909004]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-15b3c8468108>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(main, argv)\u001b[0m\n\u001b[0;32m    123\u001b[0m   \u001b[1;31m# Call the main function, passing through any arguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m   \u001b[1;31m# to the final program.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m   \u001b[0m_sys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-15b3c8468108>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(_)\u001b[0m\n\u001b[0;32m     36\u001b[0m                         \u001b[0mnx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mny\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_setup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mny\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\AI\\jupyter_files\\Autoencoder\\backward.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(nx, ny)\u001b[0m\n\u001b[0;32m    104\u001b[0m                                         \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m                                         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmerged\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m                                         \u001b[0mval_err\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_images_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_labels_test\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %load main.py\n",
    "import tensorflow as tf\n",
    "from tools import make_dir\n",
    "from tools import input_setup\n",
    "\n",
    "from backward import backward\n",
    "\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer(\"epoch\",         2000,   \"Number of epoch [15000]\")\n",
    "flags.DEFINE_integer(\"batch_size\",    1000,     \"The size of batch images [128]\")\n",
    "flags.DEFINE_integer(\"image_size\",    28,      \"The size of image to use [28]\")\n",
    "flags.DEFINE_integer(\"label_size\",    28,      \"The size of label to produce [28]\")\n",
    "flags.DEFINE_integer(\"compress_size\", 14,\t   \"The size of compress matrix to produce [14]\")\n",
    "flags.DEFINE_integer(\"c_dim\", 1, \"Dimension of image color. [1]\")\n",
    "flags.DEFINE_float(\"learning_rate\",   0.00001,   \"The learning rate of gradient descent algorithm [1e-4]\")\n",
    "flags.DEFINE_float(\"learding_rate_delay\",1,\"The learning rate decay\")\n",
    "flags.DEFINE_float(\"REGULARIZER\",0.0001,\"REGULARIZER\")\n",
    "flags.DEFINE_integer(\"scale\", 3, \"The size of scale factor for preprocessing input image [3]\")\n",
    "flags.DEFINE_integer(\"stride\", 10, \"The size of stride to apply input image [14]\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", \"checkpoint\", \"Name of checkpoint directory [checkpoint]\")\n",
    "flags.DEFINE_string(\"sample_dir\", \"sample\", \"Name of sample directory [sample]\")\n",
    "flags.DEFINE_boolean(\"is_train\", True, \"True for training, False for testing [True]\")\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "def main(_):\n",
    "\tprint(\"start.......\")\n",
    "\t\n",
    "\tmake_dir()\n",
    "\t\n",
    "\twith tf.Session() as sess:\n",
    "\t\tprint(\"compress rate is:\",sess.run(tf.square(FLAGS.compress_size / FLAGS.image_size)))\n",
    "\t\tif FLAGS.is_train:\n",
    "\t\t\tinput_setup(FLAGS)\t\t\t\t#制作数据集\n",
    "\t\t\tnx, ny = 0 , 0\n",
    "\t\telse:\n",
    "\t\t\tnx, ny = input_setup(FLAGS)\n",
    "\t\n",
    "\tbackward(nx,ny)\n",
    "\t\t\n",
    "\t\n",
    "if __name__ == '__main__':\n",
    "\ttf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "4\n",
      "2\n",
      "5\n",
      "3\n",
      "6\n",
      "[[1, 4], [2, 5], [3, 6]]\n",
      "[[2, 5], [1, 4], [3, 6]]\n",
      "[[1, 4], [2, 5], [3, 6]]\n",
      "[[3, 6], [1, 4], [2, 5]]\n",
      "[[1, 4], [2, 5], [3, 6]]\n",
      "[1, 4]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "a = [1,2,3]\n",
    "b = [4,5,6]\n",
    "\n",
    "c = []\n",
    "\n",
    "for i in range(len(a)):\n",
    "    print(a[i])\n",
    "    print(b[i])\n",
    "    c.append([a[i],b[i]])\n",
    "print(c)\n",
    "random.shuffle(c)\n",
    "print(c)\n",
    "random.shuffle(c)\n",
    "print(c)\n",
    "random.shuffle(c)\n",
    "print(c)\n",
    "random.shuffle(c)\n",
    "print(c)\n",
    "\n",
    "d = c[0]\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
